if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("phyloseq")
BiocManager::install("phyloseq")
BiocManager::install("biomformat")
numCores <- detectCores()
registerDoMC(cores=numCores)
metadataSamplesAll <- read.csv("tcga_metadata_poore_et_al_2020_1Aug23.csv", row.names = 1)
# Load tables from Gihawi et al. listed here:
# https://github.com/yge15/Cancer_Microbiome_Reanalyzed
blcaKraken <- read.csv("TableS8_BLCA.all.csv",
row.names = 1, stringsAsFactors = FALSE)
hnscKraken <- read.csv("TableS9_HNSC_all.csv",
row.names = 1, stringsAsFactors = FALSE)
colnames(hnscKraken) <- gsub("^g_","",colnames(hnscKraken)) # Uniformize genera names
brcaKraken <- read.csv("TableS10_BRCA_WGS.csv",
row.names = 1, stringsAsFactors = FALSE)
colnames(brcaKraken) <- gsub("^g_","",colnames(brcaKraken))  # Uniformize genera names
#------------------------------------------------------#
# Load Weizmann (WIS) data summarized at genus level and subset Kraken features
# NOTE: WIS genera come from highly decontaminated 16S and ITS data, as published
# in Nejman et al. 2020 Science and Narunsky-Haziza et al. 2022 Cell
#------------------------------------------------------#
## Load WIS genera from 'hit list'
load("Supporting_files/wis-bacteria-fungi-genera-species-bio-24July22.RData", verbose = TRUE)
wisGenera <- data.frame(tax_table(psWzBacteriaAndFungi_genus_Bio))
wisGeneraKnown <- wisGenera %>%
filter(!grepl("Unknown",genus)) %>%
filter(!grepl("other",genus)) %>%
droplevels()
wisGeneraKnownUnique <- unique(wisGeneraKnown$genus)
length(unique(wisGeneraKnownUnique)) # 437
## Subset tables
sum(colnames(blcaKraken) %in% wisGeneraKnownUnique) # 151
sum(colnames(hnscKraken) %in% wisGeneraKnownUnique) # 161
sum(colnames(brcaKraken) %in% wisGeneraKnownUnique) # 159
blcaKrakenWIS <- blcaKraken[,colnames(blcaKraken) %in% wisGeneraKnownUnique]
hnscKrakenWIS <- hnscKraken[,colnames(hnscKraken) %in% wisGeneraKnownUnique]
brcaKrakenWIS <- brcaKraken[,colnames(brcaKraken) %in% wisGeneraKnownUnique]
#------------------------------------------------------#
# Merge tables
# - Selected conservative method to retain only overlapping features
# (although that reduce some effect size since the files are
# separated by cancer type)
# - Note that WIS did not contain "Homo" genus calls, so they are inherently excluded
#------------------------------------------------------#
sharedFeat <- Reduce(intersect, list(colnames(blcaKrakenWIS),
colnames(hnscKrakenWIS),
colnames(brcaKrakenWIS)))
countMergedWIS <- smartbind(blcaKrakenWIS[,sharedFeat],
hnscKrakenWIS[,sharedFeat],
brcaKrakenWIS[,sharedFeat])
# Missing values after the merge should be converted to 0s
countMergedWIS[is.na(countMergedWIS)] <- 0
rownames(countMergedWIS) <- c(rownames(blcaKrakenWIS),
rownames(hnscKrakenWIS),
rownames(brcaKrakenWIS))
dim(countMergedWIS) # 728 149
# Subset metadata to samples reflected by Gihawi et al. 2023
metadataSamplesMergedWIS <- metadataSamplesAll[rownames(countMergedWIS),]
# Subset to primary tumor ("PT") and blod derived normal ("BDN") samples
metadataSamplesMergedWIS_PT <- metadataSamplesMergedWIS %>%
filter(sample_type == "Primary Tumor") %>% droplevels()
metadataSamplesMergedWIS_BDN <- metadataSamplesMergedWIS %>%
filter(sample_type == "Blood Derived Normal") %>% droplevels()
# Count PT subsets
metadataSamplesMergedWIS_PT %>% count(data_submitting_center_label, investigation)
metadataSamplesMergedWIS_PT_HMS <- metadataSamplesMergedWIS_PT %>%
filter(data_submitting_center_label == "Harvard Medical School") %>%
select(investigation, disease_type, experimental_strategy,data_submitting_center_label) %>%
rownames_to_column("sampleid") %>%
droplevels()
countMergedWIS_PT_HMS <- countMergedWIS[metadataSamplesMergedWIS_PT_HMS$sampleid,]
metadataSamplesMergedWIS_PT_Broad <- metadataSamplesMergedWIS_PT %>%
filter(data_submitting_center_label == "Broad Institute of MIT and Harvard") %>%
select(investigation, disease_type, experimental_strategy,data_submitting_center_label) %>%
rownames_to_column("sampleid") %>%
droplevels()
countMergedWIS_PT_Broad <- countMergedWIS[metadataSamplesMergedWIS_PT_Broad$sampleid,]
metadataSamplesMergedWIS_PT_MDA <- metadataSamplesMergedWIS_PT %>%
filter(data_submitting_center_label == "MD Anderson - Institute for Applied Cancer Science") %>%
select(investigation, disease_type, experimental_strategy,data_submitting_center_label) %>%
rownames_to_column("sampleid") %>%
filter(investigation != "TCGA-BRCA") %>% # Drop the 2 samples
droplevels()
countMergedWIS_PT_MDA <- countMergedWIS[metadataSamplesMergedWIS_PT_MDA$sampleid,]
#------------------------------------------------------#
# Examine BDN sequencing center subsets
#
# NOTE: The goal is to have individual seq-center subsets
# to avoid needing batch correction. This allows us to use
# the raw data for comparisons.
#------------------------------------------------------#
metadataSamplesMergedWIS_BDN %>% count(data_submitting_center_label, investigation)
metadataSamplesMergedWIS_BDN_HMS <- metadataSamplesMergedWIS_BDN %>%
filter(data_submitting_center_label == "Harvard Medical School") %>%
select(investigation, disease_type, experimental_strategy,data_submitting_center_label) %>%
rownames_to_column("sampleid") %>%
droplevels()
countMergedWIS_BDN_HMS <- countMergedWIS[metadataSamplesMergedWIS_BDN_HMS$sampleid,]
#------------------------------------------------------#
# For completeness - sequencing platform
#
# - NOTE: 1 sample was processed on a MiSeq, but it was at WashU,
# which is not included in the PT or BDN subsets (so ignore)
#------------------------------------------------------#
metadataSamplesMergedWIS %>% count(platform, data_submitting_center_label)
#----------------------------------------------------------#
# PT multi-class machine learning
#
# NOTE: Since HMS is the only seq-center subset that had 3 cancer types,
# it will be the only multi-class ML instance
#----------------------------------------------------------#
require(caret) # for model building (6.0-90)
require(gbm) # for machine learning (2.1.8)
require(xgboost) # for machine learning (1.5.0.1)
require(randomForest) # for machine learning (4.6-14)
require(PRROC) # for precision-recall curves (1.3.1)
require(MLmetrics) # for multi-class learning (1.1.1)
## Write ML function
mlMulticlass <- function(metaData = metadataSamplesMergedWIS_PT_HMS,
countData = countMergedWIS_PT_HMS,
sampleType = "Primary Tumor",
seqCenter = "Harvard Medical School",
modelType = "xgbTree",
numResampleIter = 1,
numKFold = 10){
st <- gsub('([[:punct:]])|\\s+','',sampleType)
sc <- gsub('([[:punct:]])|\\s+','',seqCenter)
numSeed <- 42
xgbGrid <- data.frame(nrounds = 10,
max_depth = 4,
eta = .1,
gamma = 0,
colsample_bytree = .7,
min_child_weight = 1,
subsample = .8)
metaDataFilt <- metaData %>% column_to_rownames("sampleid")
metaDataFilt$predY <- factor(gsub("^TCGA-","",metaDataFilt$investigation))
countData <- countData[rownames(metaDataFilt),] # re-align in case
mlDataY <- metaDataFilt
mlDataX <- countData
# Use cross-validation:
trainX <- mlDataX
trainY <- mlDataY[,"predY"]
print(table(trainY))
set.seed(numSeed) # have to restate seed again,
# as ctrl defines the cross validation sampling during training
ctrl <- trainControl(method = "repeatedcv",
number = numKFold,
repeats = numResampleIter,
sampling = "up",
summaryFunction = multiClassSummary,
classProbs = TRUE,
verboseIter = FALSE,
savePredictions = TRUE,
allowParallel=TRUE)
print("Now training model...")
set.seed(numSeed)
mlModel <- train(x = trainX,
y = trainY,
method = modelType,
# preProcess = c("zv"), # remove zero variance features
nthread = 1,
trControl = trainControl(method = "repeatedcv",
number = numKFold,
repeats = numResampleIter,
sampling = "up",
summaryFunction = multiClassSummary,
classProbs = TRUE,
verboseIter = FALSE,
savePredictions = TRUE,
allowParallel=TRUE),
# metric = "ROC",
tuneGrid = xgbGrid,
verbose = FALSE)
resPredFun <- function(mlModel){
resPred <- mlModel$pred
## Split folds and calculate perf on each fold
resPredSplit <- split(resPred, resPred$Resample)
repX_perf <- list()
for(zz in seq_along(resPredSplit)){
resPredSingleRep <- resPredSplit[[zz]]
predProbs <- resPredSingleRep
multiClass <- resPredSingleRep
rep_perfTmp <- multiClassSummary(multiClass, lev = levels(multiClass$obs))
repX_perf[[zz]] <- data.frame(as.list(rep_perfTmp))
}
# SUMMARIZE MODEL PERFORMANCES
rep_perf <- do.call(rbind, repX_perf)
# print(rep_perf)
return(rep_perf)
}
print("Obtaining performance values...")
resPredAll <- mlModel$pred
perfCombinedAll <-  multiClassSummary(resPredAll, lev = levels(resPredAll$obs))
repPerfCombinedAll <- resPredFun(mlModel)
## Save predictions and perf
# Preds
baseFilename <- paste0("multiclassCV_WIS_",st,"_",sc,"_k",numKFold,"_modelType_",modelType)
write.csv(resPredAll, file = paste0("ML_results/pred",baseFilename,".csv"))
save(resPredAll, file = paste0("ML_results/pred",baseFilename,".RData"))
# Overall perf
write.csv(perfCombinedAll, file = paste0("ML_results/perfCombinedAll",baseFilename,".csv"))
save(perfCombinedAll, file = paste0("ML_results/perfCombinedAll",baseFilename,".RData"))
# Rep perf
write.csv(resPredAll, file = paste0("ML_results/repPerfCombinedAll",baseFilename,".csv"))
save(resPredAll, file = paste0("ML_results/repPerfCombinedAll",baseFilename,".RData"))
## Variable importances
xgb_imp <- as.data.frame(xgb.importance(feature_names = mlModel$finalModel$feature_names,
model = mlModel$finalModel))
write.csv(xgb_imp, file = paste0("ML_results/featureImp",baseFilename,".csv"))
# Print top 5 features
print("Top feature importances:")
print(head(xgb_imp))
res <- list(resPredAll=resPredAll,
mlModel=mlModel,
varImp=xgb_imp,
perfCombinedAll=perfCombinedAll,
repPerfCombinedAll=repPerfCombinedAll)
return(res)
rm(mlModel)
}
# Call multiclass function
hmsMulticlassMLRes_PT <- mlMulticlass()
# Examine overall performance:
hmsMulticlassMLRes_PT$perfCombinedAll
# Examine per-CV performance:
hmsMulticlassMLRes_PT$repPerfCombinedAll
# Create confusion matrix
caret::confusionMatrix(hmsMulticlassMLRes_PT$resPredAll$pred,
hmsMulticlassMLRes_PT$resPredAll$obs)
# Call multiclass function
hmsMulticlassMLRes_BDN <- mlMulticlass(metaData = metadataSamplesMergedWIS_BDN_HMS,
countData = countMergedWIS_BDN_HMS,
sampleType = "Blood Derived Normal",
seqCenter = "Harvard Medical School",
modelType = "xgbTree",
numResampleIter = 1,
numKFold = 10)
# Examine overall performance:
hmsMulticlassMLRes_BDN$perfCombinedAll
# Examine per-CV performance:
hmsMulticlassMLRes_BDN$repPerfCombinedAll
# Create confusion matrix
caret::confusionMatrix(hmsMulticlassMLRes_BDN$resPredAll$pred,
hmsMulticlassMLRes_BDN$resPredAll$obs)
# Confusion Matrix and Statistics
# Confusion Matrix and Statistics
#
# Confusion Matrix and Statistics
#
# Reference
# Confusion Matrix and Statistics
#
# Reference
# Prediction BRCA HNSC
# Confusion Matrix and Statistics
#
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# Confusion Matrix and Statistics
#
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
# Confusion Matrix and Statistics
#
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
#
# Confusion Matrix and Statistics
#
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
#
# Accuracy : 0.9474
# Confusion Matrix and Statistics
#
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# Confusion Matrix and Statistics
#
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
#
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
# Reference
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Prediction BRCA HNSC
# BRCA   15    1
# HNSC    4   75
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
# BRCA   15    1
# HNSC    4   75
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
#
# HNSC    4   75
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
# Accuracy : 0.9474
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
# 95% CI : (0.8814, 0.9827)
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
# No Information Rate : 0.8
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
# P-Value [Acc > NIR] : 4.444e-05
#
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
# Kappa : 0.8252
#
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
# Mcnemar's Test P-Value : 0.3711
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#        'Positive' Class : BRCA
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#        'Positive' Class : BRCA
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#        'Positive' Class : BRCA
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#        'Positive' Class : BRCA
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#        'Positive' Class : BRCA
#             Sensitivity : 0.7895
#             Specificity : 0.9868
#          Pos Pred Value : 0.9375
#          Neg Pred Value : 0.9494
#              Prevalence : 0.2000
#          Detection Rate : 0.1579
#    Detection Prevalence : 0.1684
#       Balanced Accuracy : 0.8882
#
#        'Positive' Class : BRCA
